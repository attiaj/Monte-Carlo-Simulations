{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3:\n",
    "\n",
    "For part 1, we need to find the best constant c($\\lambda$) for the AR method. Taking Exp($\\lambda$) as our g(x) function, we calculate $\\frac{f(x)}{g(x)}$, then take the derivative to find the maximum value that this function can take. The derivative = 0 when x = 0 (minimum possible value of x) or when x* = $\\frac{2}{1-\\lambda}$, which is our maximum value. Therefore, $\\frac{f(x)}{g(x)}$ must be less than or equal to its evaluation at x*, and we get c($\\lambda$) = $\\frac{f(x*)}{g(x*)}$ = $\\frac{2e^{-2}}{\\lambda(1-\\lambda)^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For part 2, we want to make the AR method the most efficient as we can: a uniform RV gets accepted if it's less than $\\frac{f(X)}{cg(X)}$. The probability of acceptance is the expected value of this formula, which comes out to be $\\frac{1}{c}$. Therefore, if we want our probability of acceptance to be the highest possible value, we need to minimize c, to maximize the acceptance rate. If we take the derivative of our c($\\lambda$) function, set it equal to 0, we get $\\lambda$* = 1/3. From a boundary check, we verify that this is a minimum, and thus our optimal $\\lambda$*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For part 3, we first define c with our optimal $\\lambda$*, f(x), and g(x), then calculated the true Expected Value of f(x) to be $\\int_0^\\infty x \\cdot \\frac{1}{2}x^2 e^{-x} dx$ = 3. Using this true mean, we can compare our sample means for differing numbers of samples to see when we start to experience diminishing returns.\n",
    "\n",
    "The algorithm runs a for loop for each value of n = 10^1, 10^2, ... 10^7. In each case we use AR method, taking only accepted samples into a list, then computing our sample mean. \n",
    "\n",
    "We seem to begin experiencing diminishing returns around n = 10^5, where our sample mean is 3.0077, and n = 10^6's sample mean is 2.9985. We start to gain only small amounts of accuracy in a tradeoff for exceptionally long computation times, with n = 10^7 producing sample mean of 3.0003 in return for about 3 full minutes of computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
